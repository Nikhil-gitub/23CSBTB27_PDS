{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGE/nIJlys/sF4q4ySqGS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhil-gitub/23CSBTB27_PDS/blob/main/Reinforcement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "DATA_PATH = \"stocks.csv\"\n",
        "HIGH_VOL_PERCENTILE = 90\n",
        "ROLL_WINDOW = 5\n",
        "TEST_SIZE = 0.2\n",
        "SEED = 42\n",
        "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "TABULAR_EPISODES = 5   # fewer episodes\n",
        "PG_EPOCHS, AC_EPOCHS = 1, 1   # reduced epochs for speed\n",
        "\n",
        "# ---------------- Load & preprocess ----------------\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "price_col = next((c for c in df.columns if \"price\" in c.lower()), df.select_dtypes(include=[np.number]).columns[0])\n",
        "if any(\"time\" in c.lower() or \"date\" in c.lower() for c in df.columns):\n",
        "    tcol = next(c for c in df.columns if \"time\" in c.lower() or \"date\" in c.lower())\n",
        "    df = df.sort_values(tcol)\n",
        "df['price'] = pd.to_numeric(df[price_col], errors='coerce')\n",
        "df['return'] = df['price'].pct_change().fillna(0)\n",
        "df['abs_return'] = df['return'].abs()\n",
        "df['rolling_vol'] = df['abs_return'].rolling(ROLL_WINDOW, min_periods=1).std().fillna(0)\n",
        "df['rolling_mean_ret'] = df['return'].rolling(ROLL_WINDOW, min_periods=1).mean().fillna(0)\n",
        "df['volume'] = np.random.randint(100, 1000, len(df))\n",
        "thresh = np.percentile(df['abs_return'], HIGH_VOL_PERCENTILE)\n",
        "df['high_vol_next'] = (df['abs_return'].shift(-1) > thresh).astype(int)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "features = ['price','return','rolling_vol','rolling_mean_ret','volume']\n",
        "X, y = df[features].values, df['high_vol_next'].values\n",
        "X = StandardScaler().fit_transform(X)\n",
        "split = int(len(X)*(1-TEST_SIZE))\n",
        "X_train,X_test,y_train,y_test = X[:split],X[split:],y[:split],y[split:]\n",
        "\n",
        "# ---------------- Environment ----------------\n",
        "class VolEnv:\n",
        "    def __init__(self,X,y): self.X,self.y,self.n=X,y,len(y)\n",
        "    def reset(self): self.i=0; self.done=False; return self.X[self.i]\n",
        "    def step(self,action):\n",
        "        r = 1 if action==self.y[self.i] else -1\n",
        "        self.i+=1\n",
        "        if self.i>=self.n: self.done=True; return None,r,True,{}\n",
        "        return self.X[self.i],r,False,{}\n",
        "\n",
        "# ---------------- Tabular Q ----------------\n",
        "print(\"\\n=== Tabular Q ===\")\n",
        "kbd = KBinsDiscretizer(n_bins=5,encode='ordinal',strategy='uniform')\n",
        "Xd = kbd.fit_transform(X_train)[:,:2].astype(int)\n",
        "Q = np.zeros((25,2))\n",
        "env = VolEnv(X_train,y_train)\n",
        "for _ in range(TABULAR_EPISODES):\n",
        "    s = env.reset(); si = int(Xd[0][0]*5+Xd[0][1])\n",
        "    while not env.done:\n",
        "        a = np.argmax(Q[si]) if random.random()>0.1 else random.randint(0,1)\n",
        "        _,r,done,_ = env.step(a)\n",
        "        if done: break\n",
        "        nxt = int(Xd[min(env.i,len(Xd)-1)][0]*5+Xd[min(env.i,len(Xd)-1)][1])\n",
        "        Q[si,a]+=0.5*(r+0.9*np.max(Q[nxt])-Q[si,a]); si=nxt\n",
        "preds_tab = np.argmax([Q[int(s[0]*5+s[1])] for s in kbd.transform(X_test)[:,:2]],axis=1)\n",
        "print(\"Acc:\", accuracy_score(y_test,preds_tab))\n",
        "\n",
        "# ---------------- REINFORCE ----------------\n",
        "print(\"\\n=== REINFORCE ===\")\n",
        "policy=models.Sequential([\n",
        "    layers.Input((X_train.shape[1],)),\n",
        "    layers.Dense(8,activation='relu'),  # smaller net\n",
        "    layers.Dense(2,activation='softmax')\n",
        "])\n",
        "opt=optimizers.Adam(0.001)\n",
        "def ret(r,g=0.99):\n",
        "    R=0;out=[]\n",
        "    for x in r[::-1]:\n",
        "        R=x+g*R;out.append(R)\n",
        "    out=out[::-1];return (np.array(out)-np.mean(out))/(np.std(out)+1e-8)\n",
        "for _ in range(PG_EPOCHS):\n",
        "    env=VolEnv(X_train,y_train)\n",
        "    s=env.reset().reshape(1,-1); states,acts,rews=[],[],[]\n",
        "    while not env.done:\n",
        "        p=policy(s).numpy()[0]; a=np.random.choice(2,p=p)\n",
        "        ns,r,d,_=env.step(a); states.append(s[0]); acts.append(a); rews.append(r)\n",
        "        if not d: s=ns.reshape(1,-1)\n",
        "    R=ret(rews)\n",
        "    with tf.GradientTape() as tape:\n",
        "        probs=policy(np.array(states))\n",
        "        logp=tf.math.log(tf.reduce_sum(probs*tf.one_hot(acts,2),axis=1)+1e-8)\n",
        "        loss=-tf.reduce_mean(logp*R)\n",
        "    grads=tape.gradient(loss,policy.trainable_variables)\n",
        "    opt.apply_gradients(zip(grads,policy.trainable_variables))\n",
        "preds_pg = np.argmax(policy.predict(X_test,verbose=0),axis=1)\n",
        "print(\"Acc:\",accuracy_score(y_test,preds_pg))\n",
        "\n",
        "# ---------------- Actor-Critic ----------------\n",
        "print(\"\\n=== Actor-Critic ===\")\n",
        "actor=models.Sequential([\n",
        "    layers.Input((X_train.shape[1],)),\n",
        "    layers.Dense(8,activation='relu'),  # smaller net\n",
        "    layers.Dense(2,activation='softmax')\n",
        "])\n",
        "critic=models.Sequential([\n",
        "    layers.Input((X_train.shape[1],)),\n",
        "    layers.Dense(8,activation='relu'),\n",
        "    layers.Dense(1,activation='linear')\n",
        "])\n",
        "critic.compile(optimizers.Adam(0.001),loss='mse'); aopt=optimizers.Adam(0.001)\n",
        "for _ in range(AC_EPOCHS):\n",
        "    env=VolEnv(X_train,y_train)\n",
        "    s=env.reset().reshape(1,-1); states,acts,rews=[],[],[]\n",
        "    while not env.done:\n",
        "        p=actor(s).numpy()[0]; a=np.random.choice(2,p=p)\n",
        "        ns,r,d,_=env.step(a); states.append(s[0]); acts.append(a); rews.append(r)\n",
        "        if not d: s=ns.reshape(1,-1)\n",
        "    R=ret(rews); vals=critic(np.array(states)).numpy().flatten()\n",
        "    adv=R-vals; critic.train_on_batch(np.array(states),R)\n",
        "    with tf.GradientTape() as tape:\n",
        "        probs=actor(np.array(states))\n",
        "        logp=tf.math.log(tf.reduce_sum(probs*tf.one_hot(acts,2),axis=1)+1e-8)\n",
        "        loss=-tf.reduce_mean(logp*adv)\n",
        "    grads=tape.gradient(loss,actor.trainable_variables)\n",
        "    aopt.apply_gradients(zip(grads,actor.trainable_variables))\n",
        "preds_ac = np.argmax(actor.predict(X_test,verbose=0),axis=1)\n",
        "print(\"Acc:\",accuracy_score(y_test,preds_ac))\n",
        "\n",
        "# ---------------- DQN (supervised pretrain fast) ----------------\n",
        "print(\"\\n=== DQN (supervised pretrain) ===\")\n",
        "def build_q():\n",
        "    m=models.Sequential([\n",
        "        layers.Input((X_train.shape[1],)),\n",
        "        layers.Dense(16,activation='relu'),\n",
        "        layers.Dense(2,activation='softmax')\n",
        "    ])\n",
        "    m.compile(optimizers.Adam(0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    return m\n",
        "q=build_q()\n",
        "y_train_oh=tf.keras.utils.to_categorical(y_train,2)\n",
        "q.fit(X_train,y_train_oh,epochs=5,batch_size=64,verbose=0)  # fewer epochs, bigger batch\n",
        "preds_dqn = np.argmax(q.predict(X_test,verbose=0),axis=1)\n",
        "print(\"Acc:\",accuracy_score(y_test,preds_dqn))\n",
        "\n",
        "# ---------------- Summary ----------------\n",
        "print(\"\\nSummary:\")\n",
        "for name,acc in {\n",
        "    \"TabQ\":accuracy_score(y_test,preds_tab),\n",
        "    \"REINF\":accuracy_score(y_test,preds_pg),\n",
        "    \"A2C\":accuracy_score(y_test,preds_ac),\n",
        "    \"DQN\":accuracy_score(y_test,preds_dqn)\n",
        "}.items():\n",
        "    print(f\"{name}: {acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZvqLTxWgFtm",
        "outputId": "ddf70fae-848c-4ebf-a22c-00e2b11a44a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Tabular Q ===\n",
            "Acc: 0.8907117801812335\n",
            "\n",
            "=== REINFORCE ===\n",
            "Acc: 0.5157117801812335\n",
            "\n",
            "=== Actor-Critic ===\n",
            "Acc: 0.7390382928968138\n",
            "\n",
            "=== DQN (supervised pretrain) ===\n",
            "Acc: 0.9113928675825782\n",
            "\n",
            "Summary:\n",
            "TabQ: 0.891\n",
            "REINF: 0.516\n",
            "A2C: 0.739\n",
            "DQN: 0.911\n"
          ]
        }
      ]
    }
  ]
}